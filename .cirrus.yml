---

# Main environment vars to set for all tasks
env:

    FEDORA_NAME: "fedora-36"
    FEDORA_PRIOR_NAME: "fedora-35"

    UBUNTU_NAME: "ubuntu-22.04"
    UBUNTU_PRIOR_NAME: "ubuntu-20.04"

    CENTOS_9_NAME: "centos-stream-9"
    CENTOS_8_NAME: "centos-stream-8"

    CENTOS_PROJECT: "centos-cloud"
    FEDORA_PROJECT: "fedora-cloud"
    SOS_PROJECT: "sos-devel-jobs"
    UBUNTU_PROJECT: "ubuntu-os-cloud"

    # These are generated images pushed to GCP from Red Hat
    FOREMAN_CENTOS_IMAGE_NAME: "foreman-25-centos-8-sos-testing"
    FOREMAN_DEBIAN_IMAGE_NAME: "foreman-25-debian-10-sos-testing"

    # Images exist on GCP already
    CENTOS_9_IMAGE_NAME: "centos-stream-9-v20220621"
    CENTOS_8_IMAGE_NAME: "centos-stream-8-v20220621"
    FEDORA_IMAGE_NAME: "fedora-cloud-base-gcp-36-20220506-n-0-x86-64"
    FEDORA_PRIOR_IMAGE_NAME: "fedora-cloud-base-gcp-35-1-2-x86-64"
    UBUNTU_IMAGE_NAME: "ubuntu-2204-jammy-v20220622"
    UBUNTU_PRIOR_IMAGE_NAME: "ubuntu-2004-focal-v20220701"

    # Curl-command prefix for downloading task artifacts, simply add the
    # the url-encoded task name, artifact name, and path as a suffix.
    # This approach originally seen in the podman project.
    ARTCURL: >-
        curl --fail --location -O
        --url https://api.cirrus-ci.com/v1/artifact/build/${CIRRUS_BUILD_ID}

# Default task timeout
timeout_in: 30m

# enable auto cancelling concurrent builds on main when multiple PRs are
# merged at once
auto_cancellation: true

gcp_credentials: ENCRYPTED[!77d4c8251094346c41db63cb05eba2ff98eaff04e58c5d0e2a8e2c6f159f7d601b3fe9a2a4fce1666297e371f2fc8752!]

# Run a simple lint on the community cluster
flake8_task:
    alias: "flake8_test"
    name: "Flake8 linting test"
    container:
        image: alpine/flake8:latest
    flake_script: flake8 sos

# Run a check on newer upstream python versions to check for possible
# breaks/changes in common modules. This is not meant to check any of the actual
# collections or archive integrity.
py_break_task:
    alias: "py_break"
    name: "Breakage test python-$PY_VERSION"
    container:
        image: "python:${PY_VERSION}"
    matrix:
        - env:
            PY_VERSION: "latest"
        - env:
            PY_VERSION: "3.9"
    # This image has 2 py environments. Install to the one sos uses.
    setup_script: pip3 install -t /usr/lib/python3/dist-packages -r requirements.txt
    main_script: ./bin/sos report --batch

# Make sure a user can manually build an rpm from the checkout
rpm_build_task:
    alias: "rpm_build"
    name: "rpm Build From Checkout - ${BUILD_NAME}"
    gce_instance: &standardvm
        image_project: "${PROJECT}"
        image_name: "${VM_IMAGE_NAME}"
        type: e2-medium
    matrix:
        - env: &centos9
            PROJECT: ${CENTOS_PROJECT}
            BUILD_NAME: ${CENTOS_9_NAME}
            VM_IMAGE_NAME: ${CENTOS_9_IMAGE_NAME}
        - env: &centos8
            PROJECT: ${CENTOS_PROJECT}
            BUILD_NAME: ${CENTOS_8_NAME}
            VM_IMAGE_NAME: ${CENTOS_8_IMAGE_NAME}
        - env: &fedora
            PROJECT: ${FEDORA_PROJECT}
            BUILD_NAME: ${FEDORA_NAME}
            VM_IMAGE_NAME: ${FEDORA_IMAGE_NAME}
        - env: &fedoraprior
            PROJECT: ${FEDORA_PROJECT}
            BUILD_NAME: ${FEDORA_PRIOR_NAME}
            VM_IMAGE_NAME: ${FEDORA_PRIOR_IMAGE_NAME}
    setup_script: |
        dnf clean all
        dnf -y install rpm-build rpmdevtools gettext python3-devel
    main_script: |
        mkdir -p /rpmbuild/{BUILD,BUILDROOT,RPMS,SRPMS,SOURCES}
        python3 setup.py sdist
        cp dist/sos*.tar.gz /rpmbuild/SOURCES/
        rpmbuild -bs sos.spec
        rpmbuild -bb sos.spec
    # Retrieving the built rpm in later tasks requires knowing the exact name
    # of the file. To avoid having to juggle version numbers here, rename it
    prep_artifacts_script: mv /rpmbuild/RPMS/noarch/sos-*.rpm ./sos_${BUILD_NAME}.rpm
    packages_artifacts:
        path: ./sos_${BUILD_NAME}.rpm
        type: application/octet-stream

# Make sure a user can manually build a snap from the checkout
snap_build_task:
    alias: "snap_build"
    name: "snap Build From Checkout"
    gce_instance:
        image_project: "${UBUNTU_PROJECT}"
        image_name: "${UBUNTU_PRIOR_IMAGE_NAME}"
        type: e2-medium
    setup_script: |
        apt update
        apt -y install snapd
        systemctl start snapd
        sed -i 's/adopt-info.*/version: test/g' snap/snapcraft.yaml
        snap install snapcraft --classic
    main_script: |
        snapcraft --destructive-mode
    packages_artifacts:
        path: "*.snap"

# Run the stage one (no mocking) tests across all distros on GCP
report_stageone_task:
    alias: "stageone_report"
    name: "Report Stage One - $BUILD_NAME"
    depends_on:
        - rpm_build
        - snap_build
    gce_instance: *standardvm
    matrix:
        - env: *centos9
        - env: *centos8
        - env: *fedora
        - env: *fedoraprior
        - env: &ubuntu
            PROJECT: ${UBUNTU_PROJECT}
            BUILD_NAME: ${UBUNTU_NAME}
            VM_IMAGE_NAME: ${UBUNTU_IMAGE_NAME}
        - env: &ubuntuprior
            PROJECT: ${UBUNTU_PROJECT}
            BUILD_NAME: ${UBUNTU_PRIOR_NAME}
            VM_IMAGE_NAME: ${UBUNTU_PRIOR_IMAGE_NAME}
    setup_script: &setup |
        if [ $(command -v apt) ]; then
            echo "$ARTCURL/snap%20Build%20From%20Checkout/packages/sosreport_test_amd64.snap"
            $ARTCURL/snap%20Build%20From%20Checkout/packages/sosreport_test_amd64.snap
            apt -y purge sosreport
            apt update --allow-releaseinfo-change
            apt -y install python3-pip snapd python3-magic
            systemctl start snapd
            snap install ./sosreport_test_amd64.snap --classic --dangerous
        fi
        if [ $(command -v dnf) ]; then
            echo "$ARTCURL/rpm%20Build%20From%20Checkout%20-%20${BUILD_NAME}/packages/sos_${BUILD_NAME}.rpm"
            $ARTCURL/rpm%20Build%20From%20Checkout%20-%20${BUILD_NAME}/packages/sos_${BUILD_NAME}.rpm
            dnf -y remove sos
            dnf -y install python3-pip ethtool
            dnf -y install ./sos_${BUILD_NAME}.rpm
        fi
        pip3 install avocado-framework==94.0
    # run the unittests separately as they require a different PYTHONPATH in
    # order for the imports to work properly under avocado
    unittest_script: PYTHONPATH=. avocado run tests/unittests/
    main_script: PYTHONPATH=tests/ avocado run -p TESTLOCAL=true --test-runner=runner -t stageone tests/{cleaner,collect,report,vendor}_tests
    on_failure:
        fail_script: &faillogs |
            ls -d /var/tmp/avocado* /root/avocado* 2> /dev/null | xargs tar cf sos-fail-logs.tar
        log_artifacts: &logs
            path: "sos-fail-logs.tar"

# IFF the stage one tests all pass, then run stage two for latest distros
report_stagetwo_task:
    alias: "stagetwo_report"
    name: "Report Stage Two - $BUILD_NAME"
    depends_on: stageone_report
    gce_instance: *standardvm
    matrix:
        - env: *centos9
        - env: *centos8
        - env: *fedora
        - env: *ubuntu
    setup_script: *setup
    install_pexpect_script: |
        if [ $(command -v apt) ]; then
            apt -y install python3-pexpect
        fi
        if [ $(command -v dnf) ]; then
            dnf -y install python3-pexpect
        fi
    main_script: PYTHONPATH=tests/ avocado run -p TESTLOCAL=true --test-runner=runner -t stagetwo tests/{cleaner,collect,report,vendor}_tests
    on_failure:
        fail_script: *faillogs
        log_artifacts: *logs

report_foreman_task:
    skip: "!changesInclude('.cirrus.yml', '**/{__init__,apache,foreman,foreman_tests,candlepin,pulp,pulpcore}.py')"
    alias: "foreman_integration"
    name: "Integration Test - Foreman ${FOREMAN_VER}"
    depends_on: stageone_report
    gce_instance: &bigvm
        <<: *standardvm
        type: e2-standard-2
    matrix:
        - env:
            PROJECT: ${SOS_PROJECT}
            VM_IMAGE_NAME: ${FOREMAN_CENTOS_IMAGE_NAME}
            # Use the CentOS 8 sos rpm for this task
            BUILD_NAME: ${CENTOS_8_NAME}
            FOREMAN_VER: "2.5 - CentOS Stream 8"
        - env:
            PROJECT: ${SOS_PROJECT}
            VM_IMAGE_NAME: ${FOREMAN_DEBIAN_IMAGE_NAME}
            FOREMAN_VER: "2.5 - Debian 10"
    setup_script: *setup
    main_script: PYTHONPATH=tests/ avocado run -p TESTLOCAL=true --test-runner=runner -t foreman tests/product_tests/foreman/
    on_failure:
        fail_script: *faillogs
        log_artifacts: *logs
